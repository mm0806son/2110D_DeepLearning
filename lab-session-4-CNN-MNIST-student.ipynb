{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mE2F5Cj5X-cq"
   },
   "source": [
    "# Lab session 4 | Convolutional Neural Networks (CNN) with pytorch\n",
    "\n",
    "pierre-henri.conze@imt-atlantique.fr \\\\\n",
    "francois.rousseau@imt-atlantique.fr \\\\\n",
    "simon.benaichouche@imt-atlantique.fr \\\\\n",
    "aurelien.colin@imt-atlantique.fr\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZNAqdzCX-cs"
   },
   "source": [
    "## Objective of this lab session: perform classification on MNIST using convolutional neural networks\n",
    "\n",
    "In lab session 3, MNIST classification has been performed relying on Multi-Layer Perceptron (MLP) models. The obtained accuracy was 92% with a softmax regressor and 97% (or 98%) with a deeper MLP. This can be further improved! Let us jump from such simple models to something moderately more sophisticated, namely **Convolutional Neural Networks** (CNN).\n",
    "\n",
    "For recall, **MNIST** is a computer vision dataset which consists of handwritten digit images with associated label. Each image in MNIST has a corresponding label - a number between 0 and 9 - representing the digit drawn in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85qr0BEYX-cu"
   },
   "source": [
    "### 1- Data management\n",
    "\n",
    "Start with these lines of code to automatically download the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "W6fsgjPOX-cv"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.ToTensor() # convert data to torch.FloatTensor\n",
    "\n",
    "train_data = datasets.MNIST(root = 'data', train = True, download = True, transform = transform)\n",
    "test_data = datasets.MNIST(root = 'data', train = False, download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQKjqImJ4mKx"
   },
   "source": [
    "#### **Question 1.1** - Complete the following cell to create **data loaders** ([documentation](https://pytorch.org/docs/stable/data.html)) for training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ho-I57ync1Ya"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 20 # how many samples per batch to load\n",
    "valid_size = 0.2 # percentage of training set to use as validation\n",
    "\n",
    "def create_data_loaders(batch_size, valid_size, train_data, test_data):\n",
    "# ! By ourselves\n",
    "    num_train, num_test = len(train_data), len(test_data)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size)\n",
    "    # obtain training indices that will be used for validation\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    train_index, valid_index = indices[split:], indices[:split]\n",
    "\n",
    "    # define samplers for obtaining training and validation subsets\n",
    "    train_sampler = SubsetRandomSampler(train_index)\n",
    "    valid_sampler = SubsetRandomSampler(valid_index)\n",
    "\n",
    "    # prepare data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, sampler = train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, sampler = valid_sampler)\n",
    "    return train_loader, valid_loader, test_loader\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gXWfzusFrlmQ"
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = create_data_loaders(batch_size, valid_size, train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18G47IQQX-c3"
   },
   "source": [
    "Let us visualize some images from the training set with corresponding ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "executionInfo": {
     "elapsed": 2019,
     "status": "ok",
     "timestamp": 1601150749171,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "arAFBf_q0K3p",
    "outputId": "bda651dd-5b73-4afe-ea7a-919340592e39"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "data_iter = iter(train_loader) \n",
    "images, labels = data_iter.next() # obtain one batch from the train set\n",
    "images = images.numpy()\n",
    "# plot images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray') # .npsqueeze removes single-dimensional entries from the shape of an array\n",
    "    ax.set_title(str(labels[idx].item())) # .item() gets the value contained in a Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9vqCd8jpJnE"
   },
   "source": [
    "### 2- Simple CNN architecture\n",
    "\n",
    "Let us define a simple **CNN architecture**. The network will take as inputs 28x28 images instead of 784-dimensional tensors of pixel values as for MLP models. As in lab session 3, it will produce as output a tensor of length 10 (i.e. the number of classes) that indicates the class scores for each input image. A CNN architecture is a stack of layers including:\n",
    "  - convolutional layer using *nn.Conv2D* ([documentation](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html))\n",
    "  - max-pooling layer using *nn.MaxPool2D* ([documentation](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html))\n",
    "  - regular densely-connected layer using *nn.Linear* ([documentation](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "897aqt3UyfHz"
   },
   "source": [
    "#### **Question 2.1** - In this first network architecture (*Net1*), employ:\n",
    " - 2 consecutive convolutional layers using 32 3x3 filters with stride 1 followed by *ReLU* activation,\n",
    " - a max pooling with vertical and horizontal downscale of 2,\n",
    " - a flatten operator to flatten the input array,\n",
    " - a dense layer with 10 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lLiWMnC5jBy"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net1(nn.Module):  \n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net1,self).__init__()\n",
    "        # ! By ourselves\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        # ! By ourselves\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 2210,
     "status": "ok",
     "timestamp": 1601150749537,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "OFwVrc_XT3cs",
    "outputId": "da238c36-0e52-400b-a0d5-8ce00297fa57"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device '+str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K48q4mnBKBx_"
   },
   "source": [
    "**torchsummary** provides information complementary to what is provided by *print(your_model)* in PyTorch, similar to the Tensorflow *model.summary()* routine ([documentation](https://pypi.org/project/torch-summary/)). This can be helpful while debugging your network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG8wQhudOvOE"
   },
   "source": [
    "#### **Question 2.2** - Describe input/output sizes of each layer. Confirm your analysis by using *summary()* from *torchsummary*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "executionInfo": {
     "elapsed": 6470,
     "status": "ok",
     "timestamp": 1601150753817,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "JbdKfY3h-wAy",
    "outputId": "f08d9a8e-4d36-45ad-9293-3d61375341cb"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "cnn_1 = Net1() # initialize the neural network\n",
    "cnn_1.to(device=device)\n",
    "\n",
    "summary(     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWkV71ZLI2ZO"
   },
   "source": [
    "#### **Question 2.3** - Before training a model, configure the learning process by indicating the criterion (i.e the objective loss function the model will try to minimize) as well as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeZr3uLL58Qw"
   },
   "outputs": [],
   "source": [
    "criterion = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_IkVZB-01tJ"
   },
   "outputs": [],
   "source": [
    "optimizer = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxYFf5sG0_XC"
   },
   "source": [
    "### 3- Training\n",
    "\n",
    "#### **Question 3.1** - Complete the following cell to perform the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbGZO4wt6jTR"
   },
   "outputs": [],
   "source": [
    "n_epochs = 20 # number of epochs to train the model\n",
    "\n",
    "def training(n_epochs, train_loader, valid_loader, model, criterion, optimizer):\n",
    "\n",
    "  train_losses, valid_losses = [], []\n",
    "  # initialize tracker for minimum validation loss\n",
    "  valid_loss_min = np.Inf  # set initial \"min\" to infinity\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "      train_loss, valid_loss = 0, 0 # monitor losses\n",
    "      \n",
    "      # train the model\n",
    "      model.train() # prep model for training\n",
    "      for data, label in train_loader:\n",
    "          data = data.to(device=device, dtype=torch.float32)\n",
    "          label = label.to(device=device, dtype=torch.long)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "          train_loss += loss.item() * data.size(0) # update running training loss\n",
    "      \n",
    "      # validate the model\n",
    "      model.eval()\n",
    "      for data, label in valid_loader:\n",
    "          data = data.to(device=device, dtype=torch.float32)\n",
    "          label = label.to(device=device, dtype=torch.long)\n",
    "          with torch.no_grad():\n",
    "\n",
    "            \n",
    "            \n",
    "          valid_loss += loss.item() * data.size(0)\n",
    "      \n",
    "      # calculate average loss over an epoch\n",
    "      train_loss /= len(train_loader.sampler)\n",
    "      valid_loss /= len(valid_loader.sampler)\n",
    "      train_losses.append(train_loss)\n",
    "      valid_losses.append(valid_loss)\n",
    "      \n",
    "      print('epoch: {} \\ttraining Loss: {:.6f} \\tvalidation Loss: {:.6f}'.format(epoch+1, train_loss, valid_loss))\n",
    "\n",
    "      # save model if validation loss has decreased\n",
    "      if valid_loss <= valid_loss_min:\n",
    "          print('validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "          valid_loss_min,\n",
    "          valid_loss))\n",
    "          torch.save(model.state_dict(), 'model.pt')\n",
    "          valid_loss_min = valid_loss\n",
    "      \n",
    "  return train_losses, valid_losses      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "executionInfo": {
     "elapsed": 180302,
     "status": "ok",
     "timestamp": 1601150927690,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "fulupe2f71cJ",
    "outputId": "f3c9fc23-7732-4a43-bc29-e4223b1e83e1"
   },
   "outputs": [],
   "source": [
    "train_losses_1, valid_losses_1 = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twmMCMSz1NoN"
   },
   "source": [
    "To study the **convergence** of the training process, we plot the evolution of the loss function for training and validation sets with respect to epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "executionInfo": {
     "elapsed": 180281,
     "status": "ok",
     "timestamp": 1601150927691,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "HpT1Y7cNBA5F",
    "outputId": "2c57e90a-9ff2-4770-fd31-a634544a2de9"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(n_epochs), train_losses_1)\n",
    "plt.plot(range(n_epochs), valid_losses_1)\n",
    "plt.legend(['train', 'validation'], prop={'size': 10})\n",
    "plt.title('loss function', size=10)\n",
    "plt.xlabel('epoch', size=10)\n",
    "plt.ylabel('loss value', size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1C17bsUC1W_Y"
   },
   "source": [
    "Let us load the model corresponding to the lowest validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 180263,
     "status": "ok",
     "timestamp": 1601150927692,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "qzToZJN3FBbS",
    "outputId": "9957d43f-b7ae-43db-96d1-d21b0d52f459"
   },
   "outputs": [],
   "source": [
    "cnn_1.load_state_dict(torch.load('model.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NM5BWPs_3Pbz"
   },
   "source": [
    "### 4- Testing\n",
    "\n",
    "#### **Question 4.1** - Complete the following cell to test the (best) model on previously unseen test data and evaluate its performance through per-class and global accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQIsKly4D6bw"
   },
   "outputs": [],
   "source": [
    "def evaluation(model, test_loader, criterion):\n",
    "\n",
    "  # initialize lists to monitor test loss and accuracy\n",
    "  test_loss = 0.0\n",
    "  class_correct = list(0. for i in range(10))\n",
    "  class_total = list(0. for i in range(10))\n",
    "\n",
    "  model.eval() # prep model for evaluation\n",
    "  for data, label in test_loader:\n",
    "      data = data.to(device=device, dtype=torch.float32)\n",
    "      label = label.to(device=device, dtype=torch.long)\n",
    "      with torch.no_grad():\n",
    "          output = ... # forward pass: compute predicted outputs by passing inputs to the model\n",
    "      loss = criterion( ...  )\n",
    "    \n",
    "      test_loss += loss.item()*data.size(0)\n",
    "      _, pred = torch.max(output, 1) # convert output probabilities to predicted class\n",
    "      correct = np.squeeze(pred.eq(label.data.view_as(pred))) # compare predictions to true label\n",
    "      # calculate test accuracy for each object class\n",
    "      for i in range(len(label)):\n",
    "          digit = label.data[i]\n",
    "          class_correct[digit] += correct[i].item()\n",
    "          class_total[digit] += 1\n",
    "\n",
    "  # calculate and print avg test loss\n",
    "  test_loss = test_loss/len(test_loader.sampler)\n",
    "  print('test Loss: {:.6f}\\n'.format(test_loss))\n",
    "  for i in range(10):\n",
    "      print('test accuracy of %1s: %2d%% (%2d/%2d)' % (str(i), 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "  print('\\ntest accuracy (overall): %2.2f%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total), np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 182130,
     "status": "ok",
     "timestamp": 1601150929600,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "Dc3tr9mEZ2rP",
    "outputId": "9f7a8a20-fbd8-4a46-bb1a-4e7387d8834f"
   },
   "outputs": [],
   "source": [
    "evaluation( ... ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6Qr8y1JrplH"
   },
   "source": [
    "#### **Question 4.2** - What is the overall accuracy achieved for test data? **Answer** : ... %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Brj2Tz_6QMU"
   },
   "source": [
    "### 5- Assessment\n",
    "\n",
    "The following cell displays test images and their labels in this format: predicted (ground-truth). The text will be green for accurately classified examples and red for incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7rqBNImBD-E0"
   },
   "outputs": [],
   "source": [
    "def visualization(model, test_loader):\n",
    "\n",
    "  data_iter = iter(test_loader)\n",
    "  images, labels = data_iter.next() # obtain one batch of test images\n",
    "  images = images.to(device=device, dtype=torch.float32)\n",
    "  labels = labels.to(device=device, dtype=torch.long)\n",
    "  with torch.no_grad():\n",
    "      output = model(images) # get model output\n",
    "  _, preds = torch.max(output, 1) # convert output probabilities to predicted class\n",
    "  images = images.cpu().numpy() # prep images for display\n",
    "  # plot the images in the batch, along with predicted and true labels\n",
    "  fig = plt.figure(figsize=(25, 4))\n",
    "  for idx in np.arange(20):\n",
    "      ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "      ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "      ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())), color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "executionInfo": {
     "elapsed": 182823,
     "status": "ok",
     "timestamp": 1601150930323,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "osfUv94NaEi4",
    "outputId": "b1ec8c03-0497-4eab-e420-a608ecd0967f"
   },
   "outputs": [],
   "source": [
    "visualization(cnn_1, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pbH6LzoQ9i5"
   },
   "source": [
    "Let us extract predicted (*preds*) and ground truth (*targets*) labels for images arising from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxxIS6e6KXrY"
   },
   "outputs": [],
   "source": [
    "def get_all_prediction(model, loader):\n",
    "    preds = torch.tensor([], dtype=torch.long)\n",
    "    targets = torch.tensor([], dtype=torch.long)\n",
    "    for data, label in loader:\n",
    "        data = data.to(device=device, dtype=torch.float32)\n",
    "        label = label.to(device=device, dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "        targets = torch.cat((targets, label.cpu()), dim = 0)\n",
    "        preds = torch.cat((preds, torch.max(output.cpu(), 1)[1]), dim = 0)\n",
    "    return targets.numpy(), preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g8hqY6sX64Nm"
   },
   "outputs": [],
   "source": [
    "targets, preds_1 = get_all_prediction(cnn_1, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tq8IGvWn67Rs"
   },
   "source": [
    "#### **Question 5.1** - Visualize some wrongly predicted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "executionInfo": {
     "elapsed": 184595,
     "status": "ok",
     "timestamp": 1601150932129,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "-dcFjx1QGpkm",
    "outputId": "1908a110-1ce1-4089-c2eb-fef35fccf890"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwTFkR2RX-dx"
   },
   "source": [
    "#### **Question 5.2** - Display the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zw0oafsMX-dx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "class_names= ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='confusion matrix', cmap=plt.cm.Blues):\n",
    "    # This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"normalized confusion matrix\")\n",
    "    else:\n",
    "        print('confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('true label')\n",
    "    plt.xlabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 184992,
     "status": "ok",
     "timestamp": 1601150932556,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "nkuaLoa-8jOz",
    "outputId": "7785ad57-861e-47bf-c1ac-8a5b61d29743"
   },
   "outputs": [],
   "source": [
    "# compute confusion matrix\n",
    "cnf_matrix = \n",
    "\n",
    "\n",
    "# plot normalized confusion matrix\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9AcBqA5qQ7h"
   },
   "source": [
    "### 6 - Robustness to noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3nEFKytdqvPz"
   },
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztLqmxHORxj6"
   },
   "source": [
    "Image transformations can be chained together using *Compose* ([documentation](https://pytorch.org/docs/stable/torchvision/transforms.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Kpks3nVq0lQ"
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    AddGaussianNoise(0., 0.8)\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(root = 'data', train = True, download = True, transform = transform)\n",
    "test_data = datasets.MNIST(root = 'data', train = False, download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqaBxTnLq5nQ"
   },
   "outputs": [],
   "source": [
    "train_loader_n, valid_loader_n, test_loader_n = create_data_loaders(batch_size, valid_size, train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atrFtOHzSEAM"
   },
   "source": [
    "Let us visualize some noisy images with corresponding ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "executionInfo": {
     "elapsed": 186034,
     "status": "ok",
     "timestamp": 1601150933635,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "IaIAC26CsH9R",
    "outputId": "775ac7d9-5a72-4bc5-8d22-86071b2dc012"
   },
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader_n) \n",
    "images, labels = data_iter.next() # obtain one batch from the train set\n",
    "images = images.numpy()\n",
    "# plot images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray') # .npsqueeze removes single-dimensional entries from the shape of an array\n",
    "    ax.set_title(str(labels[idx].item())) # .item() gets the value contained in a Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GIdzfq2RccF"
   },
   "source": [
    "#### **Question 6.1** - Train the network on noisy data and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "executionInfo": {
     "elapsed": 425740,
     "status": "ok",
     "timestamp": 1601151173359,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "4uNLhPjRsZom",
    "outputId": "8810d8b2-f279-4299-fb96-483b8dbc8611"
   },
   "outputs": [],
   "source": [
    "train_losses_n, valid_losses_n = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 425723,
     "status": "ok",
     "timestamp": 1601151173360,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "gGsSOrTJtAL8",
    "outputId": "71cce560-5fd9-400b-d880-23b45cea5bf2"
   },
   "outputs": [],
   "source": [
    "cnn_1.load_state_dict(torch.load('model.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 427793,
     "status": "ok",
     "timestamp": 1601151175449,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "qfz9omj3tGhD",
    "outputId": "a9533d8d-cdf9-4170-f4fe-4e861ad1eb89"
   },
   "outputs": [],
   "source": [
    "evaluation(...) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mpq2aqtw7MdR"
   },
   "source": [
    "### 7- Towards deeper CNN models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FY_2gW_3SPGY"
   },
   "source": [
    "In this last part, we come back to the original dataset, i.e. without additional noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9vHjuf_ST3q"
   },
   "source": [
    "#### **Question 7.1** - Implement a deeper convolutional neural network by adding two convolutional layers, one max pooling layer as well as dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i27yTyfnQj1t"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net2(nn.Module): \n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net2,self).__init__()\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "executionInfo": {
     "elapsed": 427769,
     "status": "ok",
     "timestamp": 1601151175451,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "TiddhzR3SkW-",
    "outputId": "c163ac47-f9d7-4a1d-e864-f450ccfd0609"
   },
   "outputs": [],
   "source": [
    "cnn_2 = Net2()\n",
    "cnn_2.to(device=device)\n",
    "\n",
    "summary(...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUP7EYwn-9lC"
   },
   "outputs": [],
   "source": [
    "optimizer = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "executionInfo": {
     "elapsed": 650304,
     "status": "ok",
     "timestamp": 1601151398013,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "xkfZoZzxStIn",
    "outputId": "5cbd9922-20b2-4857-f5bb-5359c29cb77a"
   },
   "outputs": [],
   "source": [
    "train_losses_2, valid_losses_2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 650288,
     "status": "ok",
     "timestamp": 1601151398014,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "xp_M2Lw-1L6L",
    "outputId": "65df802a-17c0-412c-9f28-ce5604ca2f91"
   },
   "outputs": [],
   "source": [
    "cnn_2.load_state_dict(torch.load('model.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3KyDic8UbmE"
   },
   "source": [
    "#### **Question 7.2** - Quantify the gain from *Net1* to *Net2* in term of overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 652435,
     "status": "ok",
     "timestamp": 1601151400179,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "Y6-N59GizdA9",
    "outputId": "f9b1b7ca-6b75-498c-8778-842f9bdde4e3"
   },
   "outputs": [],
   "source": [
    "evaluation(...) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HGAp_PrunNf"
   },
   "source": [
    "#### **Question 7.3** - What are the results for incorrect predictions arising from *Net1*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10BGrED1z6qH"
   },
   "outputs": [],
   "source": [
    "_, preds_2 = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYHp_7VYwuC7"
   },
   "source": [
    "You may display test images and labels in the following format: predicted from *Net1* (ground-truth) | predicted from *Net2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "executionInfo": {
     "elapsed": 654479,
     "status": "ok",
     "timestamp": 1601151402249,
     "user": {
      "displayName": "Pierre-Henri Conze",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhZ4Qbz7lM98QP5Y2jxN8hIcfomTY44lTm-4fcHOg=s64",
      "userId": "10921126790911374273"
     },
     "user_tz": -120
    },
    "id": "s_Yeqh9p95ti",
    "outputId": "35febc56-c642-4bf0-f0e9-b0351a4a8271"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 4))\n",
    "for i in range(20):\n",
    "  plt.subplot(2, 10, i + 1)\n",
    "  plt.axis('off')\n",
    "  plt.imshow(test_set_array[index[i],:,:], cmap='gray')\n",
    "  plt.title(\"{} ({}) | {}\".format(str(np.int(preds_1[index[i]])), str(np.int(targets[index[i]])), str(np.int(preds_2[index[i]]))), color=(\"green\" if preds_2[index[i]]==targets[index[i]] else \"red\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSu3G7LWWcde"
   },
   "source": [
    "### 8- Interactive demonstration\n",
    "\n",
    "To finish this lab session, let us play with the following interactive demo: [link](http://mnist-demo.herokuapp.com). This web application demonstrates the ability of both CNN and MLP models to classify handwritten digits.\n",
    "\n",
    "#### **Question 8.1** - Try to draw a digit which is more accurately classified by CNN than MLP. \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab-session-4-CNN-MNIST-correction.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
